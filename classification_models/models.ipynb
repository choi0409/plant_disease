{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"공모전 모델 정리.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"hxUtIO6Rt_uT"},"source":["+ 0.환경  \n","    + 1) 로컬 - pycharm  \n","    + 2) colab - gpu  \n","        \n","        \n","+ 1.데이터   \n","    + 1) 전부 올리기  \n","        + (1) 로컬   \n","        + (2) colab  \n","            \n","    + 2) 폴더에서 가져오기  \n","            \n","              \n","            \n","              \n","  \n","+ 2. 모델  \n","    + 1) 기본 cnn  \n","    + 2) Vgg 16   \n","    + 3) Inception v3   \n","    + 4) Resnet50  \n","            \n","              \n","  \n","+ 3. 역전파  \n","    + 1) optimizer  \n","    + 2) epochs / batch_size  \n","    + 3) callback\n","            \n","              \n","  \n","+ 4. report  \n","            \n","              \n","  \n","+ 5. 추후 점수 향상 방법\n","    + 1) 사진 크롭  \n","    + 2) 사진 gray 처리 \n","    + 3) 사진 비틀기\n","    "]},{"cell_type":"markdown","metadata":{"id":"NusHDsIJt_uU"},"source":["# 0.환경  "]},{"cell_type":"markdown","metadata":{"id":"TWYgel31t_uU"},"source":[" 1) 로컬 - pycharm  \n","   \n","   \n","- 장점 : 사진을 끌어오는 것이 빠르다\n","- 단점 ; gpu가 없을 시 학습이 너무 느리다\n","    "]},{"cell_type":"markdown","metadata":{"id":"6Z-LO88Jt_uV"},"source":[" 2) colab - gpu\n","   \n","   \n","- 장점 : gpu를 통해 다양한 학습을 반복시키는 것이 빠르다\n","- 단점 ; 사진을 끌어오는것이 너무 느리다\n","         하지만 한번 전부 읽어온다면 다음부터는 조금더 시간이 적게 든다\n","         - 폴더를 통해 가져오는 시간이 너무 느리다\n","         "]},{"cell_type":"code","metadata":{"id":"hWLMsqpqt_uW"},"source":["# import\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","%matplotlib inline\n","\n","np.random.seed(2)\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Conv2D, Flatten, Dense,Dropout,MaxPool2D\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","\n","\n","sns.set(style='white', context='notebook', palette='deep')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VwBEe6M9t_uZ"},"source":["# 1.데이터 \n","- x, y 모두 np 사용"]},{"cell_type":"markdown","metadata":{"id":"sESapovSt_ua"},"source":["##         1) 전부 올리기"]},{"cell_type":"code","metadata":{"id":"eoMsFQpct_ua"},"source":["# (1) 로컬에서\n","\n","# csv\n","\n","import numpy as np\n","csv_data=np.loadtxt(\"./train/train.tsv\",delimiter=\"\\t\",dtype='str')\n","\n","\n","\n","# image\n","\n","import PIL.Image as pilimg\n","pix=[]\n","for i in range(len(y_plant)):\n","    im = pilimg.open( \"./train/\"+csv_data[i][0] )\n","    #pix = np.r_[[pix],[np.array(im)]]\n","    pix.append(np.array(im))\n","    if i%100==0:\n","        print(i)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NhdWJL7Kt_uc"},"source":["# (2) colab 에서\n","\n","# csv\n","from google.colab import drive\n","import numpy as np\n","\n","drive.mount('/content/gdrive')\n","\n","csv_data = np.loadtxt(\"/content/gdrive/My Drive/~~~/filename.tsv\",delimiter=\"\\t\",dtype='str')\n","\n","\n","#image\n","import PIL.Image as pilimg\n","\n","pix=[]\n","for i in range(len(y_plant)):\n","    im = pilimg.open( \"/content/gdrive/My Drive/~~~/\"+csv_data[i][0] )\n","    pix.append(np.array(im))\n","    \n","    if i%500==0:\n","        print(i)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idN2TyvAt_uf"},"source":["# Split the train and the validation set for the fitting\n","X_train, X_val, Y_train, Y_val = train_test_split(pix, Y_data, test_size = 0.1, random_state=11)\n","\n","\n","# Without data augmentation i obtained an accuracy of 0.98114\n","history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data = (X_val, Y_val), verbose = 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rs-Uyf_1t_uh"},"source":["## 2) 폴더로 올리기"]},{"cell_type":"code","metadata":{"id":"DJWirLyct_ui"},"source":["\n","train_data_dir='/content/gdrive/My Drive/plant_disease_data/train_folder'\n","img_height=256\n","img_width=256\n","epochs = 10\n","batch_size = 100\n","\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2) # set validation split\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='training') # set as training data\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    train_data_dir, # same directory as training data\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='validation') # set as validation data\n","\n","\n","history=model.fit_generator(\n","    train_generator,\n","    steps_per_epoch = train_generator.samples // batch_size,\n","    validation_data = validation_generator, \n","    validation_steps = validation_generator.samples // batch_size,\n","    epochs = epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kirBeslGt_uk"},"source":["# 2.모델"]},{"cell_type":"markdown","metadata":{"id":"AQbisOqYt_uk"},"source":["## 1) 기본 CNN"]},{"cell_type":"code","metadata":{"id":"z0PVLSaSt_ul"},"source":["model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(128, (3, 3), activation='relu'))\n","model.add(BatchNormalization())\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(1024, activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.5))\n","model.add(Dense(20, activation='softmax')) # 2 because we have cat and dog classes\n","\n","model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n","\n","model.summary()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Br-12P0Qt_uo"},"source":["## 2) VGG 16  CNN으로 만들기"]},{"cell_type":"code","metadata":{"id":"k0QJyNcRt_uo"},"source":["from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n","\n","model=Sequential()\n","#256 244\n","model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding='same',input_shape=(256,256,3),activation='relu'))\n","model.add(MaxPool2D((2,2),strides=(2,2),padding='valid'))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(filters=128,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu'))\n","model.add(MaxPool2D((2,2),strides=(2,2),padding='valid'))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu'))\n","model.add(MaxPool2D((2,2),strides=(2,2),padding='valid'))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(filters=512,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu'))\n","model.add(MaxPool2D((2,2),strides=(2,2),padding='valid'))\n","model.add(BatchNormalization())\n","\n","model.add(Conv2D(filters=1024,kernel_size=(3,3),strides=(1,1),padding='same',activation='relu'))\n","model.add(MaxPool2D((2,2),strides=(2,2),padding='valid'))\n","model.add(BatchNormalization())\n","\n","model.add(Flatten())\n","\n","model.add(Dense(4096,activation='relu'))\n","model.add(Dropout(0.25))\n","model.add(BatchNormalization())\n","model.add(Dense(4096,activation='relu'))\n","model.add(Dropout(0.25))\n","model.add(BatchNormalization())\n","model.add(Dense(1000,activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(BatchNormalization())\n","model.add(Dense(20,activation='softmax'))\n","\n","model.summary()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VV1DvaZqt_uq"},"source":["## 3) inception v3"]},{"cell_type":"code","metadata":{"id":"0p5dmNS0t_uq"},"source":["\n","input = Input(shape=(224, 224, 3))\n","\n","model=tf.keras.applications.InceptionV3(\n","        include_top=False,\n","        weights='imagenet',\n","        input_tensor=input,\n","        input_shape=(256,256,3),\n","        pooling=None,\n","        #classes=20,\n","        #classifier_activation=\"softmax\",\n","    )\n","\n","x = model.output\n","x = tf.keras.layers.Flatten()(x)\n","x = Dense(1024, name='fully', kernel_initializer='random_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dense(512, kernel_initializer='random_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dense(20, activation='softmax', name='softmax')(x)\n","\n","model = Model(model.input, x)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IG9hKCSBt_us"},"source":["## 4) resnet50"]},{"cell_type":"code","metadata":{"id":"pLJcyBKDt_ut"},"source":["\n","from keras.applications import ResNet50\n","\n","input = Input(shape=(224, 224, 3))\n","\n","model = ResNet50(input_tensor=input, include_top=False, weights=None, pooling='max')\n","\n","x = model.output\n","x = tf.keras.layers.Flatten()(x)\n","x = Dense(1024, name='fully', kernel_initializer='random_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dense(512, kernel_initializer='random_uniform')(x)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = Dense(20, activation='softmax', name='softmax')(x)\n","\n","model = Model(model.input, x)\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zBiB_p0vt_uv"},"source":["### 모델저장 /불러오기"]},{"cell_type":"code","metadata":{"id":"YJXgQsxvt_uw"},"source":["from keras.models import load_model\n","\n","#저장\n","model.save('/content/gdrive/My Drive/resnet50a.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDBZ9N2Zt_uy"},"source":["#불러오기\n","model = load_model('/content/gdrive/My Drive/resnet50.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"scqVT4ZAt_u0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j6r7eLW1t_u3"},"source":["# 3. 역전파"]},{"cell_type":"code","metadata":{"id":"Z-fCcdp6t_u3"},"source":["# 1)\n","optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n","\n","# 2)\n","epochs = 25 # Turn epochs to 30 to get 0.9967 accuracy\n","batch_size = 100\n","\n","# Compile the model\n","model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","# 3)Callback     Set a learning rate annealer\n","learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n","                                            patience=3, \n","                                            verbose=1, \n","                                            factor=0.5, \n","                                            min_lr=0.00001)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZjzjEXht_u7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nay5KQK5t_u9"},"source":["# Without data augmentation i obtained an accuracy of 0.98114\n","history = model.fit(X_train, Y_train, \n","                    batch_size = batch_size, \n","                    epochs = epochs, \n","                    validation_data = (X_val, Y_val), \n","                    verbose = 2,\n","                    callbacks=[learning_rate_reduction]\n","                   )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HI4NH3__t_u_"},"source":["### callback도 중요한듯!"]},{"cell_type":"code","metadata":{"id":"ZSt6ttDvt_vA"},"source":["##### 빨리 끝낼수 있는 callback\n","early_stopping = EarlyStopping()\n","model.fit(X_train, Y_train, nb_epoch= 1000, callbacks=[early_stopping])\n","\n","# OR\n","\n","from keras.callbacks import ModelCheckpoint\n","checkpoint = ModelCheckpoint(weightpath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VszL6BM6t_vC"},"source":["# 4. Report"]},{"cell_type":"code","metadata":{"id":"WSnYcKMnt_vC"},"source":["fig, ax = plt.subplots(2,1)\n","ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n","ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n","legend = ax[0].legend(loc='best', shadow=True)\n","\n","ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n","ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n","legend = ax[1].legend(loc='best', shadow=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y22vwjcbt_vE"},"source":["def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, cm[i, j],\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","# Predict the values from the validation dataset\n","Y_pred = model.predict(X_val)\n","# Convert predictions classes to one hot vectors \n","Y_pred_classes = np.argmax(Y_pred,axis = 1) \n","# Convert validation observations to one hot vectors\n","Y_true = np.argmax(Y_val,axis = 1) \n","# compute the confusion matrix\n","confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n","# plot the confusion matrix\n","plot_confusion_matrix(confusion_mtx, classes = range(20)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_Oi4Ezot_vF"},"source":["from sklearn.metrics import classification_report\n","report = classification_report(Y_true, Y_pred_classes)\n","print(report)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYsecoA_t_vH"},"source":["# Display some error results \n","\n","# Errors are difference between predicted labels and true labels\n","errors = (Y_pred_classes - Y_true != 0)\n","\n","Y_pred_classes_errors = Y_pred_classes[errors]\n","Y_pred_errors = Y_pred[errors]\n","Y_true_errors = Y_true[errors]\n","X_val_errors = X_val[errors]\n","\n","def display_errors(errors_index,img_errors,pred_errors, obs_errors):\n","    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n","    n = 0\n","    nrows = 2\n","    ncols = 3\n","    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n","    for row in range(nrows):\n","        for col in range(ncols):\n","            error = errors_index[n]\n","            ax[row,col].imshow((img_errors[error]).reshape((224,224,3)))\n","            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n","            n += 1\n","\n","# Probabilities of the wrong predicted numbers\n","Y_pred_errors_prob = np.max(Y_pred_errors,axis = 1)\n","\n","# Predicted probabilities of the true values in the error set\n","true_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n","\n","# Difference between the probability of the predicted label and the true label\n","delta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n","\n","# Sorted list of the delta prob errors\n","sorted_dela_errors = np.argsort(delta_pred_true_errors)\n","\n","# Top 6 errors \n","most_important_errors = sorted_dela_errors[-6:]\n","\n","# Show the top 6 errors\n","display_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8u-TnwgZt_vJ"},"source":["# 4. 추후 점수 향상 방법"]},{"cell_type":"markdown","metadata":{"id":"DhsWICZwt_vJ"},"source":["## 1) 사진크롭"]},{"cell_type":"markdown","metadata":{"id":"1KZdJlvGt_vK"},"source":["## 2) 사진 흑백화"]},{"cell_type":"markdown","metadata":{"id":"juAlsPZvt_vL"},"source":["## 3) 사진 비틀기"]},{"cell_type":"code","metadata":{"id":"2PttpyUZt_vL"},"source":["# # With data augmentation to prevent overfitting (accuracy 0.99286)\n","\n","# datagen = ImageDataGenerator(\n","#         featurewise_center=False,  # set input mean to 0 over the dataset\n","#         samplewise_center=False,  # set each sample mean to 0\n","#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","#         samplewise_std_normalization=False,  # divide each input by its std\n","#         zca_whitening=False,  # apply ZCA whitening\n","#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","#         zoom_range = 0.1, # Randomly zoom image \n","#         width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","#         height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","#         horizontal_flip=False,  # randomly flip images\n","#         vertical_flip=False)  # randomly flip images\n","\n","\n","# datagen.fit(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TgHek9Uzt_vN"},"source":["# data_gen_train = ImageDataGenerator(rescale=1/255.)\n","\n","# data_gen_valid = ImageDataGenerator(rescale=1/255.)\n","\n","# train_generator = data_gen_train.flow_from_directory(train_dir, target_size=(128,128), batch_size=128, class_mode=\"binary\")\n","\n","# valid_generator = data_gen_valid.flow_from_directory(validation_dir, target_size=(128,128), batch_size=128, class_mode=\"binary\")\n","\n","# model.fit(train_generator, epochs=2, validation_data=valid_generator)."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uvjYxlc2t_vQ"},"source":["# # Fit the model\n","# history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n","#                               epochs = epochs, \n","#                               validation_data = (X_val,Y_val),\n","#                               verbose = 2, \n","#                               steps_per_epoch=X_train.shape[0] // batch_size,\n","#                               callbacks=[learning_rate_reduction])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OMl4tGDDt_vS"},"source":[""],"execution_count":null,"outputs":[]}]}